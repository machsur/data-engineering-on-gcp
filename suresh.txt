==============

set up environment:
setup python and configure environment variable.
setup VS code
integrate vs code with python by installing python extension on vs code...
download git repo onto our local machine (https://github.com/itversity)
setup vs code workspace for extracted repo.
setup python venv 

=========
Databricks: big data processing
1. signup for databricks from marketplace to use on GCP. then page redirected to workspaces.
2. create databricks workspace on GCP
   data bricks run on cloud platform and utilizes some resorces from underlying gcp project.
3. open workspace UI and spin up databrick clusters on GCP.(cluster mode, node type, runtime version-scala,spark)
4. getting started with databrick notebook on cluster. (do developement using python code and use magic commands to interact with databricks fs)
5. setup databricks cli/sdk or restApi for clients/servers on winodws.
6. manage databricks clusters/fs/jobs/secreats using cli
7. copy datasets from local dir to dbfs using cli
8. process data in dbfs using spark sql in notebooks
9. spark sql to find daily product revenue from the dbfs files



